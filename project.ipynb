{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /opt/conda/miniconda3/lib/python3.11/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /opt/conda/miniconda3/lib/python3.11/site-packages (from kaggle) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/miniconda3/lib/python3.11/site-packages (from kaggle) (2.9.0)\n",
      "Requirement already satisfied: requests in /opt/conda/miniconda3/lib/python3.11/site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/miniconda3/lib/python3.11/site-packages (from kaggle) (4.65.0)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/miniconda3/lib/python3.11/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/miniconda3/lib/python3.11/site-packages (from kaggle) (1.26.18)\n",
      "Requirement already satisfied: bleach in /opt/conda/miniconda3/lib/python3.11/site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/miniconda3/lib/python3.11/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/miniconda3/lib/python3.11/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests->kaggle) (3.4)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105786 sha256=1be70fb76c51bc0f2d18525571d16ff1820f7b1d30988fd5a545fb531eed71b7\n",
      "  Stored in directory: /root/.cache/pip/wheels/ff/55/fb/b27a466be754d2a06ffe0e37b248d844f090a63b51becea85d\n",
      "Successfully built kaggle\n",
      "Installing collected packages: kaggle\n",
      "Successfully installed kaggle-1.6.17\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat '/path/to/kaggle.json': No such file or directory\n",
      "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!mv /path/to/kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/cnrieiit/mqttset\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Task 1\n",
    "Fetch MQTTset from Kaggle\n",
    "'''\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Authenticate using Kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Download the dataset\n",
    "dataset = 'cnrieiit/mqttset'\n",
    "api.dataset_download_files(dataset, path='.', unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No active SparkSession found.\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "try:\n",
    "    spark = SparkSession.getActiveSession()\n",
    "    if spark is None:\n",
    "        print(\"No active SparkSession found.\")\n",
    "    else:\n",
    "        print(\"An active SparkSession is running.\")\n",
    "except Exception as e:\n",
    "    print(\"Error checking SparkSession:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "help\n"
     ]
    }
   ],
   "source": [
    "print(\"help\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/14 23:09:28 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/11/14 23:09:28 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/11/14 23:09:28 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/11/14 23:09:28 INFO SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Task 1\n",
    "Setup SparkSession and test connection to Postgres\n",
    "\n",
    "Note, you don't need all of those jars if you just ssh into the VM and run this command\n",
    "to download the cloud_sql_proxy, and point your Spark Database Connection to localhost:5432\n",
    "\n",
    "wget https://dl.google.com/cloudsql/cloud_sql_proxy.linux.amd64 -O cloud_sql_proxy\n",
    "chmod +x cloud_sql_proxy\n",
    "./cloud_sql_proxy -instances=systool-436201:us-east1:projectdb=tcp:5432 &\n",
    "\n",
    "That instance is specific to my project, but you get the idea\n",
    "'''\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit \n",
    "\n",
    "\n",
    "# Define dataset, spark constants\n",
    "APPNAME = 'Roberts_Systool_Project'\n",
    "MASTER = 'yarn'\n",
    "JDBC_JAR_PATHS = [\n",
    "    \"home/jroberts1187/course-project-option-2-aitechroberts/postgresql-42.7.4.jar\",\n",
    "]\n",
    "\n",
    "# JDBC_URL = 'jdbc:postgresql://104.196.99.150:5432/projectdb' CloudSQL URL\n",
    "'''\n",
    "Point all nodes (master and workers) to local host to run through each of their own CloudSQL Proxies\n",
    "'''\n",
    "JDBC_URL = 'jdbc:postgresql://127.0.0.1:5432/postgres'\n",
    "DB_PROPERTIES = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres_pw\",\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "    \"batchsize\": \"10000\" # trying to optimize the write and seems to have cut the time in half\n",
    "}\n",
    "\n",
    "# Initialize Spark session with PostgreSQL JDBC driver\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(APPNAME) \\\n",
    "    .master(MASTER) \\\n",
    "    .config('spark.jars',JDBC_JAR_PATHS[0]) \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"512m\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Local Spark Configuration\n",
    "# # Initialize Spark session with PostgreSQL JDBC driver\n",
    "# spark = SparkSession.builder \\\n",
    "#     .appName(APPNAME) \\\n",
    "#     .master(MASTER)\\\n",
    "#     .config('spark.driver.host','127.0.0.1')\\  \n",
    "#     .config(\"spark.jars\", JDBC_JAR_PATHS[0]) \\\n",
    "#     .config(\"spark.driver.memory\", \"4g\") \\  \n",
    "#     .config(\"spark.executor.memory\", \"3g\") \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "# df = spark.read.jdbc(url=JDBC_URL, table=\"mqtt\", properties=DB_PROPERTIES)\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "# SparkContext.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simple_df = spark.range(1000)\n",
    "simple_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|val|\n",
      "+---+\n",
      "|  3|\n",
      "+---+\n",
      "\n",
      "Connection to PostgreSQL database successful!\n"
     ]
    }
   ],
   "source": [
    "JDBC_URL = 'jdbc:postgresql://127.0.0.1:5432/postgres'\n",
    "# Add the JAR to the current SparkSession\n",
    "DB_PROPERTIES = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres_pw\",\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "    \"connectTimeout\": \"10\",\n",
    "    \"batchsize\": \"10000\" # trying to optimize the write and seems to have cut the time in half in local\n",
    "}\n",
    "\n",
    "try:\n",
    "    df = spark.read.jdbc(url=JDBC_URL, table='test', properties=DB_PROPERTIES)\n",
    "    df.show()  # This should display a single row with \"3\" if the connection is successful\n",
    "    print(\"Connection to PostgreSQL database successful!\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to connect to PostgreSQL database:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Task 1\n",
    "Ingest data with Spark and write to Postgres\n",
    "\n",
    "Creates a dictionary for data files and associated data category,\n",
    "then loops over both values using .items() method\n",
    "\n",
    "In the loop, it dynamically changes the data category and write mode\n",
    "based on where the code executes in the loop. First loop overwrites\n",
    "to create table and schema if not already exists. Second loop appends\n",
    "\n",
    "Trying optimizations for fun, repartitioning with the rule of thumb of\n",
    "2x the number of cores and using 3 of the 4 cores while leaving 1 for\n",
    "other processes increased speed by about 55-60% from 12mins to about\n",
    "5.75mins. Including batchsize of 10,000 also just about cut the time\n",
    "in half from there down to right at 2 minutes and 45 seconds.\n",
    "'''\n",
    "import os\n",
    "\n",
    "\n",
    "COL_NAMES = [\n",
    "    'tcp_flags', 'tcp_time_delta', 'tcp_len', 'mqtt_conack_flags', \n",
    "    'mqtt_conack_flags_reserved', 'mqtt_conack_flags_sp', 'mqtt_conack_val', \n",
    "    'mqtt_conflag_cleansess', 'mqtt_conflag_passwd', 'mqtt_conflag_qos', \n",
    "    'mqtt_conflag_reserved', 'mqtt_conflag_retain', 'mqtt_conflag_uname', \n",
    "    'mqtt_conflag_willflag', 'mqtt_conflags', 'mqtt_dupflag', 'mqtt_hdrflags', \n",
    "    'mqtt_kalive', 'mqtt_len', 'mqtt_msg', 'mqtt_msgid', 'mqtt_msgtype', \n",
    "    'mqtt_proto_len', 'mqtt_protoname', 'mqtt_qos', 'mqtt_retain', \n",
    "    'mqtt_sub_qos', 'mqtt_suback_qos', 'mqtt_ver', 'mqtt_willmsg', \n",
    "    'mqtt_willmsg_len', 'mqtt_willtopic', 'mqtt_willtopic_len', 'target'\n",
    "]\n",
    "\n",
    "# LOCAL_DATA_FOLDER = \"./Data/FINAL_CSV\" # won't change due to mqttset zip\n",
    "HDFS_DATA_FOLDER = \"hdfs://cluster-893d-m/user/hadoop/Data/FINAL_CSV\"\n",
    "\n",
    "data_files = {\n",
    "    'train70_augmented.csv': 'train',\n",
    "    'test30_augmented.csv': 'test'\n",
    "}\n",
    "overwrite = True\n",
    "for file, set_type_value in data_files.items():\n",
    "    # Use the 'file://' prefix to ensure Spark reads from the local file system rather than searching HDFS because I didn't put the data there.\n",
    "    file_path = os.path.join(HDFS_DATA_FOLDER, file)\n",
    "    \n",
    "    # Read CSV file\n",
    "    df = spark.read.csv(file_path, header=False, inferSchema=True).toDF(*COL_NAMES)\n",
    "    \n",
    "    # Read the CSV with header\n",
    "    df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "    # Rename columns to match COL_NAMES\n",
    "    for old_name, new_name in zip(df.columns, COL_NAMES):\n",
    "        df = df.withColumnRenamed(old_name, new_name)\n",
    "        \n",
    "    # Add 'set_type' column and dataset value of 'train' or 'test' based on place in dictionary loop\n",
    "    df = df.withColumn('set_type', lit(set_type_value))\n",
    "    \n",
    "    df.repartition(16)\n",
    "    # Show first row for verification\n",
    "    # df.show(1)\n",
    "    \n",
    "    # Overwrite on the first loop and append on the rest\n",
    "    write_mode = 'overwrite' if overwrite else 'append'\n",
    "    \n",
    "    # Write data to Postgres\n",
    "    df.write.jdbc(url=JDBC_URL, \n",
    "                  table=\"mqtt\", \n",
    "                  mode=write_mode, \n",
    "                  properties=DB_PROPERTIES,\n",
    "                  )\n",
    "    \n",
    "    # Set overwrite to False after the first write\n",
    "    if overwrite:\n",
    "        overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Task 2\n",
    "Ingest Data from Postgres into Spark for Data Analysis\n",
    "'''\n",
    "num_partitions = 16 # Adjust based on your environment which is 8 cores on Dataproc currently\n",
    "mqtt_df = spark.read.jdbc(url=JDBC_URL,\n",
    "                          table=\"mqtt\",\n",
    "                          properties=DB_PROPERTIES,\n",
    "                          numPartitions=num_partitions,\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: 20000000, 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Number of rows\n",
    "num_rows = mqtt_df.count()\n",
    "\n",
    "# Number of columns\n",
    "num_cols = len(mqtt_df.columns)\n",
    "\n",
    "print(f\"Shape: {num_rows}, {num_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tcp_flags: string (nullable = true)\n",
      " |-- tcp_time_delta: double (nullable = true)\n",
      " |-- tcp_len: integer (nullable = true)\n",
      " |-- mqtt_conack_flags: string (nullable = true)\n",
      " |-- mqtt_conack_flags_reserved: double (nullable = true)\n",
      " |-- mqtt_conack_flags_sp: double (nullable = true)\n",
      " |-- mqtt_conack_val: double (nullable = true)\n",
      " |-- mqtt_conflag_cleansess: double (nullable = true)\n",
      " |-- mqtt_conflag_passwd: double (nullable = true)\n",
      " |-- mqtt_conflag_qos: double (nullable = true)\n",
      " |-- mqtt_conflag_reserved: double (nullable = true)\n",
      " |-- mqtt_conflag_retain: double (nullable = true)\n",
      " |-- mqtt_conflag_uname: double (nullable = true)\n",
      " |-- mqtt_conflag_willflag: double (nullable = true)\n",
      " |-- mqtt_conflags: string (nullable = true)\n",
      " |-- mqtt_dupflag: double (nullable = true)\n",
      " |-- mqtt_hdrflags: string (nullable = true)\n",
      " |-- mqtt_kalive: double (nullable = true)\n",
      " |-- mqtt_len: double (nullable = true)\n",
      " |-- mqtt_msg: string (nullable = true)\n",
      " |-- mqtt_msgid: double (nullable = true)\n",
      " |-- mqtt_msgtype: double (nullable = true)\n",
      " |-- mqtt_proto_len: double (nullable = true)\n",
      " |-- mqtt_protoname: string (nullable = true)\n",
      " |-- mqtt_qos: double (nullable = true)\n",
      " |-- mqtt_retain: double (nullable = true)\n",
      " |-- mqtt_sub_qos: double (nullable = true)\n",
      " |-- mqtt_suback_qos: double (nullable = true)\n",
      " |-- mqtt_ver: double (nullable = true)\n",
      " |-- mqtt_willmsg: double (nullable = true)\n",
      " |-- mqtt_willmsg_len: double (nullable = true)\n",
      " |-- mqtt_willtopic: double (nullable = true)\n",
      " |-- mqtt_willtopic_len: double (nullable = true)\n",
      " |-- target: string (nullable = true)\n",
      " |-- set_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mqtt_df.printSchema()\n",
    "\n",
    "# print target col values\n",
    "# mqtt_df.select(\"target\").distinct().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MQTT message length is: 83.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Task 2 \n",
    "1. Find the average length of an MQTT message captured in\n",
    "the training dataset for a given target X?\n",
    "\n",
    "Also trying to use best practices in defining functions for employers\n",
    "Most analytics will be on the test set when possible to limit processing\n",
    "when possible and should be large enough, but data engineering will require the whole dataset\n",
    "'''\n",
    "from pyspark.sql.functions import col, avg, length\n",
    "\n",
    "\n",
    "def get_average_len(df, type_set='train', target=None):\n",
    "    '''\n",
    "    Function filters the dataset as much as possible using input parameters\n",
    "    then aggregates the average mqtt message length and returns that integer value\n",
    "\n",
    "    :param set: 'train' or 'test' in mqtt_df\n",
    "    :param target: 'slowite', 'bruteforce', 'flood', 'malformed', 'dos', 'legitimate'\n",
    "    \n",
    "    return: int\n",
    "    '''\n",
    "    if type_set not in ('test', 'train'):\n",
    "        raise ValueError(\"set parameter must be 'train' or 'test'\")\n",
    "    elif target not in ('slowite', 'bruteforce', 'flood', 'malformed', 'dos', 'legitimate'):\n",
    "        raise ValueError(\"target parameter must be one of these: 'slowite', 'bruteforce', 'flood', 'malformed', 'dos', 'legitimate'\")\n",
    "    \n",
    "    '''\n",
    "    I think it would be get to .cache() and unpersist(), but I'm afraid I'll break local memory\n",
    "    so I'll also filter and select to make dataframe as small as possible beforehand\n",
    "    '''\n",
    "    len_df = df.filter((col('set_type') == type_set) & (col('target') == target)).select('mqtt_msg').cache()\n",
    "    \n",
    "    # get the right column, then len of values in column, then average, all in an aggregate Spark action method, and .agg() requires .alias()\n",
    "    avg_len = len_df.agg(avg(length(col('mqtt_msg'))).alias('average_length')).collect()\n",
    "    len_df.unpersist()\n",
    "    return avg_len[0]['average_length']\n",
    "\n",
    "print(f\"Average MQTT message length is: {get_average_len(mqtt_df, target='dos'):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/11 19:35:09 WARN CacheManager: Asked to cache already cached data.        \n",
      "24/11/11 19:35:09 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malformed', 'slowite', 'bruteforce', 'legitimate', 'dos', 'flood']\n",
      "malformed\n",
      "running through function\n",
      "0x00000030\n",
      "1.7946348733233979\n",
      "slowite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running through function\n",
      "0\n",
      "1.335095567303782\n",
      "bruteforce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running through function\n",
      "0x00000010\n",
      "1.5\n",
      "legitimate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running through function\n",
      "0x00000030\n",
      "1.9717988709457337\n",
      "dos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running through function\n",
      "0x00000040\n",
      "2.418047699773572\n",
      "flood\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running through function\n",
      "0x00000030\n",
      "4.842741935483871\n",
      "Average TCP message length for target value malformed is: 1.79 \n",
      " and the most popular header value for malformed is: 0x00000030\n",
      "Average TCP message length for target value slowite is: 1.34 \n",
      " and the most popular header value for slowite is: 0\n",
      "Average TCP message length for target value bruteforce is: 1.50 \n",
      " and the most popular header value for bruteforce is: 0x00000010\n",
      "Average TCP message length for target value legitimate is: 1.97 \n",
      " and the most popular header value for legitimate is: 0x00000030\n",
      "Average TCP message length for target value dos is: 2.42 \n",
      " and the most popular header value for dos is: 0x00000040\n",
      "Average TCP message length for target value flood is: 4.84 \n",
      " and the most popular header value for flood is: 0x00000030\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Task 2 \n",
    "2. For each target value, \n",
    "1) what is the average length of TCP messages and \n",
    "2) what is the most popular header flags’ code (mqtt.hdrflags)?\n",
    "\n",
    "Given the task, it seems no other parameters are necessary\n",
    "'''\n",
    "from pyspark.sql.functions import col, avg, length\n",
    "\n",
    "\n",
    "def get_all_avg_tcp_len(df):\n",
    "    '''\n",
    "    Function loops over each unique value in the target column\n",
    "    to add the average tcp message length to a dictionary and\n",
    "    returns a dictionary with the avg tcp message length for\n",
    "    each target value and that target's most popular hdrflag\n",
    "    placed in a dictionary of tuples where [0]=tcp_len and\n",
    "    [1]=popular_header \n",
    "\n",
    "    Example: {'target':(50, 'hdrflag_val')}\n",
    "\n",
    "    return: dict\n",
    "    '''\n",
    "    answer = {}\n",
    "    targets = [row[0] for row in mqtt_df.select('target').distinct().collect()]\n",
    "    targets = targets[1:]\n",
    "    # filters for tcp messages and pulls only necessary columns\n",
    "    tcp_df = df.filter((col('tcp_len') != 0)  & (col('mqtt_hdrflags').isNotNull())).select('target', 'tcp_len', 'mqtt_hdrflags').cache()\n",
    "    \n",
    "    print(targets)\n",
    "    # Loop over every unique value in target column to get avg tcp_len and top mqtt_hdrflag value\n",
    "    for target in targets:\n",
    "        print(target)\n",
    "        # Filter by target, then get average length\n",
    "        target_df = tcp_df.filter(col('target') == target).cache()\n",
    "                         \n",
    "        tcp_len = target_df.agg(avg(length(col('tcp_len'))).alias('average_length')).collect()\n",
    "        pop_hdr = target_df.groupBy('mqtt_hdrflags').count().orderBy(col('count').desc()).first()\n",
    "        \n",
    "#         # If no mqtt_hdrflags were found, set a default value for pop_hdr\n",
    "#         if pop_hdr:\n",
    "#             hdrflag_val = pop_hdr['mqtt_hdrflags']\n",
    "#         else:\n",
    "#             hdrflag_val = \"No hdrflags found\"\n",
    "        \n",
    "        answer[target] = (tcp_len[0]['average_length'], pop_hdr['mqtt_hdrflags'])\n",
    "        print(\"running through function\")\n",
    "        print(pop_hdr['mqtt_hdrflags'])\n",
    "        print(tcp_len[0]['average_length'])\n",
    "        target_df.unpersist()\n",
    "    # get the right column, then len of values in column, then average, all in an aggregate Spark action method, and .agg() requires .alias()\n",
    "    tcp_df.unpersist()\n",
    "    return answer\n",
    "\n",
    "ans = get_all_avg_tcp_len(mqtt_df)\n",
    "keys = ans.keys()\n",
    "for key in keys:\n",
    "    print(f\"Average TCP message length for target value {key} is: {ans[key][0]:.2f} \\n and the most popular header value for {key} is: {ans[key][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequenXt flags for tcp_time_delta < Y are:\n",
      "0x00000010\n",
      "0x00000018\n",
      "0x00000002\n",
      "0x00000011\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Task 2. \n",
    "3. What is the most frequent X TCP flags for traffic with TCP time delta that is smaller than or equal to Y.\n",
    "- [] X represents a positive integer. Handle scenarios where a user may send\n",
    "negative values to your function.\n",
    "- [] Y represents a float value between 0.0 and 5.0.\n",
    "- [] Make sure to handle this scenario as well: if the user requests 5 most frequent TCP flags but there are 3 Flags that share the same count at rank number 5, please include all of them in your output.\n",
    "\n",
    "Believing that most frequent X means top X(int) TCP Flags and ranks were not asked for, funtion returns a list of flags\n",
    "'''\n",
    "\n",
    "def get_most_frequent_flags(df, X: int, Y: float):\n",
    "    '''\n",
    "    Function filters for tcp_flags and tcp_time_delta to minimize data\n",
    "    for processing. Handles errors by raisng ValueErrors and includes rank\n",
    "    ties as they appear.\n",
    "\n",
    "    return: list\n",
    "    '''\n",
    "    if 0 >= X:\n",
    "        raise ValueError(\"X must be a positive integer.\")\n",
    "    if not (5.0 >= Y >= 0.0):\n",
    "        raise ValueError(\"Y must be a float between 0.0 and 5.0.\")\n",
    "    \n",
    "    # Filter by tcp_time_delta less than Y, then count values in tcp_flags and collect rows\n",
    "    flags_df = df.filter(col('tcp_time_delta') <= Y).select('tcp_flags')\n",
    "    desc_flags = flags_df.groupBy('tcp_flags').count().orderBy(col('count').desc()).collect()\n",
    "\n",
    "    top_flags = []\n",
    "    for i, row in enumerate(desc_flags):\n",
    "        # Continue until X int is reached or if the previous row count equals the current row counts to add ties\n",
    "        if X > i or row['count'] == desc_flags[i - 1]['count']:\n",
    "            top_flags.append(row['tcp_flags'])\n",
    "    return top_flags\n",
    "\n",
    "flags = get_most_frequent_flags(mqtt_df, X=4, Y=.003)\n",
    "print('The most frequent flags for tcp_time_delta < Y are:')\n",
    "for flag in flags:\n",
    "    print(f'{flag}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Task 2.\n",
    "4. Show a histogram for the target values in the training, testing or combined\n",
    "dataset.\n",
    "- [] Your code should accept an argument that defines if the histogram is\n",
    "shown for the training, testing or combined.\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, avg, length\n",
    "\n",
    "\n",
    "def create_target_hist(df, set_type='test'):\n",
    "    '''\n",
    "    Function ensures correct parameters, filters for the target column\n",
    "    based on the set_type: 'test', 'train' or combined. Puts values\n",
    "    from target column into list. Then creates a histogram\n",
    "\n",
    "    return: None\n",
    "    '''\n",
    "    if set_type not in ('test', 'train', 'combined'):\n",
    "        raise ValueError(\"set parameter must be 'train', 'test' or 'combined'\")\n",
    "\n",
    "    # if set_type != 'combined':\n",
    "    #     hist_df = df.filter(col('set_type') == set_type).select('target')\n",
    "    # else:\n",
    "    #     hist_df = df.select('target')\n",
    "        \n",
    "    if set_type != 'combined':\n",
    "        hist_df = df.filter((col('set_type') == set_type) & (col('target') != 'target')).select('target')\n",
    "    else:\n",
    "        hist_df = df.filter(col('target') != 'target').select('target')\n",
    "\n",
    "    # test_df = spark.createDataFrame([(\"example\",), (\"test\",)], [\"target\"])\n",
    "    # test_pdf = test_df.toPandas()\n",
    "    # print(test_pdf)\n",
    "\n",
    "    # Convert to Pandas DataFrame\n",
    "    pdf = hist_df.limit(100).toPandas()\n",
    "    # Plot the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    pdf['target'].value_counts().plot(kind='bar', edgecolor='black')\n",
    "    plt.title(f'Target Value Distribution ({set_type.capitalize()} Set)')\n",
    "    plt.xlabel('Target Values')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels if needed\n",
    "    plt.tight_layout()  # Adjust layout to prevent label overlap\n",
    "    plt.show()\n",
    "\n",
    "# create_target_hist(mqtt_df)\n",
    "# create_target_hist(mqtt_df, set_type='train')\n",
    "create_target_hist(mqtt_df, set_type='combined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mstop()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 774:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Feature': 'tcp_flags', 'Observations': 20000000, 'Unique Values': 8, 'Variable Type': 'string', '1st Value Density (%)': 49.528214999999996, 'Feature Type': 'Categorical'}, {'Feature': 'mqtt_conack_flags', 'Observations': 20000000, 'Unique Values': 2, 'Variable Type': 'string', '1st Value Density (%)': 97.21346, 'Feature Type': 'Flag'}, {'Feature': 'mqtt_conack_flags_reserved', 'Observations': 20000000, 'Unique Values': 1, 'Variable Type': 'double', '1st Value Density (%)': 100.0, 'Feature Type': 'Superfluous'}, {'Feature': 'mqtt_conack_flags_sp', 'Observations': 20000000, 'Unique Values': 1, 'Variable Type': 'double', '1st Value Density (%)': 100.0, 'Feature Type': 'Superfluous'}, {'Feature': 'mqtt_conack_val', 'Observations': 20000000, 'Unique Values': 2, 'Variable Type': 'double', '1st Value Density (%)': 99.00571000000001, 'Feature Type': 'Flag'}, {'Feature': 'mqtt_conflag_cleansess', 'Observations': 20000000, 'Unique Values': 2, 'Variable Type': 'double', '1st Value Density (%)': 97.20971, 'Feature Type': 'Flag'}, {'Feature': 'mqtt_conflag_passwd', 'Observations': 20000000, 'Unique Values': 2, 'Variable Type': 'double', '1st Value Density (%)': 99.01143, 'Feature Type': 'Flag'}, {'Feature': 'mqtt_conflag_qos', 'Observations': 20000000, 'Unique Values': 1, 'Variable Type': 'double', '1st Value Density (%)': 100.0, 'Feature Type': 'Superfluous'}, {'Feature': 'mqtt_conflag_reserved', 'Observations': 20000000, 'Unique Values': 1, 'Variable Type': 'double', '1st Value Density (%)': 100.0, 'Feature Type': 'Superfluous'}, {'Feature': 'mqtt_conflag_retain', 'Observations': 20000000, 'Unique Values': 1, 'Variable Type': 'double', '1st Value Density (%)': 100.0, 'Feature Type': 'Superfluous'}, {'Feature': 'mqtt_conflag_uname', 'Observations': 20000000, 'Unique Values': 2, 'Variable Type': 'double', '1st Value Density (%)': 99.00856999999999, 'Feature Type': 'Flag'}, {'Feature': 'mqtt_conflag_willflag', 'Observations': 20000000, 'Unique Values': 1, 'Variable Type': 'double', '1st Value Density (%)': 100.0, 'Feature Type': 'Superfluous'}, {'Feature': 'mqtt_conflags', 'Observations': 20000000, 'Unique Values': 4, 'Variable Type': 'string', '1st Value Density (%)': 97.20971, 'Feature Type': 'Categorical'}, {'Feature': 'mqtt_dupflag', 'Observations': 20000000, 'Unique Values': 2, 'Variable Type': 'double', '1st Value Density (%)': 98.578895, 'Feature Type': 'Flag'}, {'Feature': 'mqtt_hdrflags', 'Observations': 20000000, 'Unique Values': 14, 'Variable Type': 'string', '1st Value Density (%)': 48.971575, 'Feature Type': 'Categorical - High Cardinality'}, {'Feature': 'mqtt_kalive', 'Observations': 20000000, 'Unique Values': 7, 'Variable Type': 'double', '1st Value Density (%)': 97.20971, 'Feature Type': 'Categorical'}, {'Feature': 'mqtt_msgtype', 'Observations': 20000000, 'Unique Values': 11, 'Variable Type': 'double', '1st Value Density (%)': 48.971575, 'Feature Type': 'Categorical - High Cardinality'}, {'Feature': 'mqtt_proto_len', 'Observations': 20000000, 'Unique Values': 2, 'Variable Type': 'double', '1st Value Density (%)': 97.20971, 'Feature Type': 'Flag'}, {'Feature': 'mqtt_protoname', 'Observations': 20000000, 'Unique Values': 2, 'Variable Type': 'string', '1st Value Density (%)': 97.20971, 'Feature Type': 'Flag'}, {'Feature': 'mqtt_qos', 'Observations': 20000000, 'Unique Values': 2, 'Variable Type': 'double', '1st Value Density (%)': 95.820265, 'Feature Type': 'Flag'}, {'Feature': 'mqtt_retain', 'Observations': 20000000, 'Unique Values': 2, 'Variable Type': 'double', '1st Value Density (%)': 99.889, 'Feature Type': 'Flag'}, {'Feature': 'mqtt_sub_qos', 'Observations': 20000000, 'Unique Values': 1, 'Variable Type': 'double', '1st Value Density (%)': 100.0, 'Feature Type': 'Superfluous'}, {'Feature': 'mqtt_suback_qos', 'Observations': 20000000, 'Unique Values': 1, 'Variable Type': 'double', '1st Value Density (%)': 100.0, 'Feature Type': 'Superfluous'}, {'Feature': 'mqtt_ver', 'Observations': 20000000, 'Unique Values': 2, 'Variable Type': 'double', '1st Value Density (%)': 97.20971, 'Feature Type': 'Flag'}, {'Feature': 'mqtt_willmsg', 'Observations': 20000000, 'Unique Values': 1, 'Variable Type': 'double', '1st Value Density (%)': 100.0, 'Feature Type': 'Superfluous'}, {'Feature': 'mqtt_willmsg_len', 'Observations': 20000000, 'Unique Values': 1, 'Variable Type': 'double', '1st Value Density (%)': 100.0, 'Feature Type': 'Superfluous'}, {'Feature': 'mqtt_willtopic', 'Observations': 20000000, 'Unique Values': 1, 'Variable Type': 'double', '1st Value Density (%)': 100.0, 'Feature Type': 'Superfluous'}, {'Feature': 'mqtt_willtopic_len', 'Observations': 20000000, 'Unique Values': 1, 'Variable Type': 'double', '1st Value Density (%)': 100.0, 'Feature Type': 'Superfluous'}, {'Feature': 'target', 'Observations': 20000000, 'Unique Values': 6, 'Variable Type': 'string', '1st Value Density (%)': 50.0, 'Feature Type': 'Categorical'}, {'Feature': 'set_type', 'Observations': 20000000, 'Unique Values': 2, 'Variable Type': 'string', '1st Value Density (%)': 70.0, 'Feature Type': 'Flag'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Task 3\n",
    "\n",
    "After conducting research on the dataset as a popular one for ML learning\n",
    "I discovered an approach to EDA a bit different than the one we covered\n",
    "in class which first conducts a unique value count across all of the features.\n",
    "So here I will start with unique value counts. This has the added benefit of\n",
    "confirming columns with only 2 values so that we can binary encode these columns\n",
    "to save memory.\n",
    "\n",
    "Importantly, here we confirm that there are no nulls in the dataset as expected,\n",
    "determine if the number of unique values matches what we expect as well, then\n",
    "groupby the occurrence of the most popular feature in a column vs the total count\n",
    "to see how much of the column actually contains useful information.\n",
    "\n",
    "The following columns all should have a lot of unique values as the individual message,\n",
    "message length, the timing of those messages, the unique ids, and the actual message\n",
    "so I will exclude them from this step\n",
    "mqtt_msg, mqtt_len, tcp_len, tcp_time_delta, mqtt_msgid\n",
    "\n",
    "Feature Engineering: Exploratory Data Analysis\n",
    "'''\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, avg, length\n",
    "\n",
    "\n",
    "def conduct_eda(df, features=[]):\n",
    "    if not features:\n",
    "        features = df.columns\n",
    "    \n",
    "    # Observations count\n",
    "    obs_count = df.count()\n",
    "    \n",
    "    exempt_features = ['mqtt_len','tcp_len','tcp_time_delta','mqtt_msgid','mqtt_msg']\n",
    "    # For each column, collect data structure information\n",
    "    structure_data = []\n",
    "\n",
    "    for feature in features:\n",
    "        if feature not in exempt_features:\n",
    "            \n",
    "            feature_info = {}\n",
    "\n",
    "            # Observations and Missing Values\n",
    "            feature_info['Feature'] = feature\n",
    "            feature_info['Observations'] = obs_count\n",
    "\n",
    "            # Unique Values\n",
    "            feature_info['Unique Values'] = df.select(feature).distinct().count()\n",
    "\n",
    "            # Variable Type\n",
    "            feature_info['Variable Type'] = dict(df.dtypes).get(feature)\n",
    "\n",
    "            # First Value Density\n",
    "            first_val = df.groupBy(feature).count().orderBy(col(\"count\").desc()).first()\n",
    "            first_density = (first_val[\"count\"] / obs_count) * 100 if first_val else 0\n",
    "            feature_info['1st Value Density (%)'] = first_density\n",
    "\n",
    "            # Feature Type based on unique count\n",
    "            if feature_info['Unique Values'] == 1:\n",
    "                feature_info['Feature Type'] = \"Superfluous\"\n",
    "            elif feature_info['Unique Values'] == 2:\n",
    "                feature_info['Feature Type'] = \"Flag\"\n",
    "            elif feature_info['Unique Values'] <= 10:\n",
    "                feature_info['Feature Type'] = \"Categorical\"\n",
    "            else:\n",
    "                feature_info['Feature Type'] = \"Categorical - High Cardinality\"\n",
    "\n",
    "            structure_data.append(feature_info)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return structure_data\n",
    "\n",
    "eda_data = conduct_eda(mqtt_df)\n",
    "\n",
    "print(eda_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Feature  Observations  Unique Values Variable Type  1st Value Density (%)                   Feature Type\n",
      "                 tcp_flags      20000000              8        string              49.528215                    Categorical\n",
      "         mqtt_conack_flags      20000000              2        string              97.213460                           Flag\n",
      "mqtt_conack_flags_reserved      20000000              1        double             100.000000                    Superfluous\n",
      "      mqtt_conack_flags_sp      20000000              1        double             100.000000                    Superfluous\n",
      "           mqtt_conack_val      20000000              2        double              99.005710                           Flag\n",
      "    mqtt_conflag_cleansess      20000000              2        double              97.209710                           Flag\n",
      "       mqtt_conflag_passwd      20000000              2        double              99.011430                           Flag\n",
      "          mqtt_conflag_qos      20000000              1        double             100.000000                    Superfluous\n",
      "     mqtt_conflag_reserved      20000000              1        double             100.000000                    Superfluous\n",
      "       mqtt_conflag_retain      20000000              1        double             100.000000                    Superfluous\n",
      "        mqtt_conflag_uname      20000000              2        double              99.008570                           Flag\n",
      "     mqtt_conflag_willflag      20000000              1        double             100.000000                    Superfluous\n",
      "             mqtt_conflags      20000000              4        string              97.209710                    Categorical\n",
      "              mqtt_dupflag      20000000              2        double              98.578895                           Flag\n",
      "             mqtt_hdrflags      20000000             14        string              48.971575 Categorical - High Cardinality\n",
      "               mqtt_kalive      20000000              7        double              97.209710                    Categorical\n",
      "              mqtt_msgtype      20000000             11        double              48.971575 Categorical - High Cardinality\n",
      "            mqtt_proto_len      20000000              2        double              97.209710                           Flag\n",
      "            mqtt_protoname      20000000              2        string              97.209710                           Flag\n",
      "                  mqtt_qos      20000000              2        double              95.820265                           Flag\n",
      "               mqtt_retain      20000000              2        double              99.889000                           Flag\n",
      "              mqtt_sub_qos      20000000              1        double             100.000000                    Superfluous\n",
      "           mqtt_suback_qos      20000000              1        double             100.000000                    Superfluous\n",
      "                  mqtt_ver      20000000              2        double              97.209710                           Flag\n",
      "              mqtt_willmsg      20000000              1        double             100.000000                    Superfluous\n",
      "          mqtt_willmsg_len      20000000              1        double             100.000000                    Superfluous\n",
      "            mqtt_willtopic      20000000              1        double             100.000000                    Superfluous\n",
      "        mqtt_willtopic_len      20000000              1        double             100.000000                    Superfluous\n",
      "                    target      20000000              6        string              50.000000                    Categorical\n",
      "                  set_type      20000000              2        string              70.000000                           Flag\n"
     ]
    }
   ],
   "source": [
    "# eda_data = conduct_eda(mqtt_df)\n",
    "\n",
    "# Assuming eda_list is your list of dictionaries\n",
    "eda_df = pd.DataFrame(eda_data)\n",
    "\n",
    "# Print the DataFrame with formatted display options\n",
    "print(eda_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|mqtt_protoname|\n",
      "+--------------+\n",
      "|             0|\n",
      "|          MQTT|\n",
      "+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|mqtt_ver|\n",
      "+--------+\n",
      "|     4.0|\n",
      "|     0.0|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|mqtt_protoname|\n",
      "+--------------+\n",
      "|             0|\n",
      "|          MQTT|\n",
      "+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|mqtt_proto_len|\n",
      "+--------------+\n",
      "|           4.0|\n",
      "|           0.0|\n",
      "+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|mqtt_kalive|\n",
      "+-----------+\n",
      "|        1.0|\n",
      "|      234.0|\n",
      "|       60.0|\n",
      "|    65535.0|\n",
      "|        2.0|\n",
      "|        0.0|\n",
      "|        3.0|\n",
      "+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|mqtt_conflags|\n",
      "+-------------+\n",
      "|   0x00000002|\n",
      "|            0|\n",
      "|   0x000000c2|\n",
      "|   0x00000082|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|mqtt_conflag_cleansess|\n",
      "+----------------------+\n",
      "|                   1.0|\n",
      "|                   0.0|\n",
      "+----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|mqtt_conack_flags|\n",
      "+-----------------+\n",
      "|                0|\n",
      "|       0x00000000|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|mqtt_hdrflags|\n",
      "+-------------+\n",
      "|   0x00000090|\n",
      "|   0x00000040|\n",
      "|   0x00000031|\n",
      "|            0|\n",
      "|   0x000000d0|\n",
      "|   0x00000010|\n",
      "|   0x00000030|\n",
      "|   0x000000e0|\n",
      "|   0x00000020|\n",
      "|   0x00000032|\n",
      "|   0x000000c0|\n",
      "|   0x00000082|\n",
      "|   0x0000003a|\n",
      "|   0x00000050|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|mqtt_retain|\n",
      "+-----------+\n",
      "|        1.0|\n",
      "|        0.0|\n",
      "+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|mqtt_dupflag|\n",
      "+------------+\n",
      "|         1.0|\n",
      "|         0.0|\n",
      "+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 828:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|mqtt_qos|\n",
      "+--------+\n",
      "|     1.0|\n",
      "|     0.0|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Using the above information we can see that there are some columns where the most popular value\n",
    "occurs 100% of the time despite the dataset containing nearly 40% of attacks so this value\n",
    "will not be useful, those columns are all of the 'will message' (which simply tells\n",
    "the broker what to publish if the client unexpectedly disconnects), the 'reserved' which should\n",
    "always be 0 and as you can see contain no useful information, the conflag retain and willflag\n",
    "columns which only contain information on what to retain or do with the willflag so also\n",
    "worthless, the mqtt quality of service columns except for mqtt_qos, and the mqtt_conack_flags_sp\n",
    "column, and finally, I'm also dropping the mqtt_msgid column as it's simply an ID and will contain\n",
    "no useful information.\n",
    "\n",
    "    'mqtt_willmsg',\n",
    "    'mqtt_willmsg_len',\n",
    "    'mqtt_willtopic',\n",
    "    'mqtt_willtopic_len',\n",
    "    'mqtt_conack_flags_reserved',\n",
    "    'mqtt_conflag_reserved',\n",
    "    'mqtt_conflag_retained',\n",
    "    'mqtt_conflag_willflag',\n",
    "    'mqtt_conflag_qos',\n",
    "    'mqtt_sub_qos',\n",
    "    'mqtt_suback_qos',\n",
    "    'mqtt_conack_flags_sp',\n",
    "    'mqtt_msgid'\n",
    "\n",
    "After that, we examine the columns which all have the most popular value\n",
    "as 97.2097% of the data because it's likely that those columns all capture\n",
    "the same information, and we could only keep one to reduce correlation and\n",
    "computational expense. Likely keeping mqtt_kalive **already out of columns_to_drop**\n",
    "\n",
    "'mqtt_ver',\n",
    "'mqtt_protoname',\n",
    "'mqtt_proto_len',\n",
    "'mqtt_kalive',\n",
    "'mqtt_conflags',\n",
    "'mqtt_conflag_cleansess',\n",
    "'mqtt_conack_flags'\n",
    "'''\n",
    "\n",
    "maybes = [\n",
    "    'mqtt_ver',\n",
    "    'mqtt_protoname',\n",
    "    'mqtt_proto_len',\n",
    "    'mqtt_kalive',\n",
    "    'mqtt_conflags',\n",
    "    'mqtt_conflag_cleansess',\n",
    "    'mqtt_conack_flags'\n",
    "    ]\n",
    "\n",
    "for maybe in maybes:\n",
    "    maybe_df = mqtt_df.select(maybe).distinct()\n",
    "    mabye_df.show()\n",
    "\n",
    "'''\n",
    "Following that my assumption based on the data descriptions is that the data\n",
    "captured in the mqtt_hdrflags column is a collection of multiple other flag\n",
    "columns mqtt_retain, mqtt_dupflag, mqtt_qos so we'll see\n",
    "'''\n",
    "\n",
    "flags = [\n",
    "    'mqtt_hdrflags',\n",
    "    'mqtt_retain',\n",
    "    'mqtt_dupflag',\n",
    "    'mqtt_qos',\n",
    "    ]\n",
    "\n",
    "for flag in flags:\n",
    "    flag_df = mqtt_df.select(feature).distinct()\n",
    "    flag_df.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    'mqtt_willmsg',\n",
    "    'mqtt_willmsg_len',\n",
    "    'mqtt_willtopic',\n",
    "    'mqtt_willtopic_len',\n",
    "    'mqtt_conack_flags_reserved',\n",
    "    'mqtt_conflag_reserved',\n",
    "    'mqtt_conflag_retain',\n",
    "    'mqtt_conflag_willflag',\n",
    "    'mqtt_conflag_qos',\n",
    "    'mqtt_sub_qos',\n",
    "    'mqtt_suback_qos',\n",
    "    'mqtt_conack_flags_sp',\n",
    "    'mqtt_msgid',\n",
    "    'mqtt_ver',\n",
    "    'mqtt_protoname',\n",
    "    'mqtt_proto_len',\n",
    "    'mqtt_conflags',\n",
    "    'mqtt_conflag_cleansess',\n",
    "    'mqtt_conack_flags',\n",
    "    'mqtt_dupflag',\n",
    "    'mqtt_retain',\n",
    "    'mqtt_qos',\n",
    "    'mqtt_msg'\n",
    "]\n",
    "\n",
    "cleaned_df = cleaned_df.drop(*cols_to_drop)\n",
    "cleaned_df.write.jdbc(url=JDBC_URL,\n",
    "                      table=\"cleaned\",\n",
    "                      mode='overwrite',\n",
    "                      properties=DB_PROPERTIES,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_partitions = 16 # Adjust based on your environment which is 8 cores on Dataproc currently\n",
    "cleaned_df = spark.read.jdbc(url=JDBC_URL,\n",
    "                          table='cleaned',\n",
    "                          properties=DB_PROPERTIES,\n",
    "                          numPartitions=num_partitions,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: 20000000, 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Number of rows\n",
    "num_clean_rows = cleaned_df.count()\n",
    "\n",
    "# Number of columns\n",
    "num_clean_cols = len(cleaned_df.columns)\n",
    "\n",
    "print(f\"Shape: {num_clean_rows}, {num_clean_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tcp_flags: string (nullable = true)\n",
      " |-- tcp_time_delta: double (nullable = true)\n",
      " |-- tcp_len: integer (nullable = true)\n",
      " |-- mqtt_conack_val: double (nullable = true)\n",
      " |-- mqtt_conflag_passwd: double (nullable = true)\n",
      " |-- mqtt_conflag_uname: double (nullable = true)\n",
      " |-- mqtt_hdrflags: string (nullable = true)\n",
      " |-- mqtt_kalive: double (nullable = true)\n",
      " |-- mqtt_len: double (nullable = true)\n",
      " |-- mqtt_msgtype: double (nullable = true)\n",
      " |-- target: string (nullable = true)\n",
      " |-- set_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "| tcp_flags|\n",
      "+----------+\n",
      "|0x00000018|\n",
      "|0x00000019|\n",
      "|0x00000002|\n",
      "|0x00000014|\n",
      "|0x00000010|\n",
      "|0x00000012|\n",
      "|0x00000011|\n",
      "|0x00000004|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|mqtt_conack_val|\n",
      "+---------------+\n",
      "|            5.0|\n",
      "|            0.0|\n",
      "+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|mqtt_conflag_passwd|\n",
      "+-------------------+\n",
      "|                1.0|\n",
      "|                0.0|\n",
      "+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|mqtt_conflag_uname|\n",
      "+------------------+\n",
      "|               1.0|\n",
      "|               0.0|\n",
      "+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|mqtt_msgtype|\n",
      "+------------+\n",
      "|         1.0|\n",
      "|        13.0|\n",
      "|         5.0|\n",
      "|         2.0|\n",
      "|         4.0|\n",
      "|        14.0|\n",
      "|         8.0|\n",
      "|         0.0|\n",
      "|         3.0|\n",
      "|         9.0|\n",
      "|        12.0|\n",
      "+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "remaining_cols = cleaned_df.columns\n",
    "\n",
    "no_check_cols = [ 'tcp_len', 'mqtt_len', 'mqtt_hdrflags', 'tcp_time_delta', 'mqtt_kalive', 'target', 'set_type']\n",
    "non_continuous_cols =  [col[0] for col in cleaned_df.dtypes if col[0] not in no_check_cols]\n",
    "for feature in non_continuous_cols:\n",
    "    feature_df = cleaned_df.select(feature).distinct()\n",
    "    feature_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tcp_flags: string (nullable = true)\n",
      " |-- tcp_time_delta: double (nullable = true)\n",
      " |-- tcp_len: integer (nullable = true)\n",
      " |-- mqtt_conack_val: integer (nullable = true)\n",
      " |-- mqtt_conflag_passwd: integer (nullable = true)\n",
      " |-- mqtt_conflag_uname: integer (nullable = true)\n",
      " |-- mqtt_hdrflags: string (nullable = true)\n",
      " |-- mqtt_kalive: string (nullable = true)\n",
      " |-- mqtt_len: integer (nullable = true)\n",
      " |-- mqtt_msgtype: string (nullable = true)\n",
      " |-- target: string (nullable = true)\n",
      " |-- set_type: string (nullable = true)\n",
      "\n",
      "['tcp_time_delta', 'tcp_len', 'mqtt_len']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Finalize the binary categorical, and numerical columns for analysis and\n",
    "future encoding.\n",
    "\n",
    "Having produced the values above, I am casting the following columns to\n",
    "integer to save memory space going from double to int because the first 3\n",
    "are binary while the mqtt_len column should be an integer anyway:\n",
    "'mqtt_conflag_uname', 'mqtt_conflag_passwd', 'mqtt_conack_val', 'mqtt_len'\n",
    "\n",
    "I am casting the following columns from double to string as they are\n",
    "meant to be categorical rather than numerical:\n",
    "'mqtt_kalive', 'mqtt_msg_type'\n",
    "'''\n",
    "from pyspark.sql.functions import col, avg, length\n",
    "\n",
    "\n",
    "# Define columns to cast to integer and string\n",
    "int_cols = ['mqtt_conack_val', 'mqtt_conflag_uname', 'mqtt_conflag_passwd', 'mqtt_len']\n",
    "str_cols = ['mqtt_kalive', 'mqtt_msgtype']\n",
    "\n",
    "# Cast integer columns\n",
    "for column in int_cols:\n",
    "    cleaned_df = cleaned_df.withColumn(column, col(column).cast('integer'))\n",
    "\n",
    "# Cast string columns\n",
    "for column in str_cols:\n",
    "    cleaned_df = cleaned_df.withColumn(column, col(column).cast('string'))\n",
    "\n",
    "# Verify the schema to ensure changes are applied\n",
    "cleaned_df.printSchema()\n",
    "# print(cleaned_df.dtypes)\n",
    "binary_cols = ['mqtt_conflag_uname', 'mqtt_conflag_passwd', 'mqtt_conack_val',]\n",
    "nominal_cols = [ 'mqtt_msgtype', 'tcp_flags', 'mqtt_hdrflags', 'mqtt_kalive',]\n",
    "labels = 'target'\n",
    "train_test = 'set_type'\n",
    "continuous_cols = ['tcp_time_delta', 'tcp_len', 'mqtt_len']\n",
    "\n",
    "print(continous_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation matrix:\n",
      " [[ 1.          0.0420559  -0.01527093]\n",
      " [ 0.0420559   1.          0.03922767]\n",
      " [-0.01527093  0.03922767  1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Task 3\n",
    "\n",
    "It's important to note here that we shouldn't actually have to\n",
    "calculate and consider outliers as here, we are not trying to\n",
    "predict a specific numerical outcome based on weights like we did\n",
    "in the plays.csv in HW4 where a larger numeric column could have\n",
    "an outsized weight effect on a given prediction if an outlier were\n",
    "to be input. Here, we actually want outliers because the goal\n",
    "is to train a classifier to identify anomalies to normal behavior\n",
    "and it is far more likely that the outliers relate to attacks in\n",
    "this dataset than negatively affect the prediction accuracy.\n",
    "\n",
    "So instead, we'll keep all data and move to correlation analysis,\n",
    "and here I use a heatmap rather than a pairplot, as the correlation\n",
    "calculation is already computationally expensive, and a pairplot\n",
    "would make it even more so. Additionally, even with only a 5%\n",
    "sample of the data and an 8 core 32GB single node, Spark kept\n",
    "crashing from the attempted collection of partitions to pandas, so\n",
    "I'm using Spark's Correlation method with Vector Assembler which\n",
    "should also serve to also go ahead and vectorize the numerical data.\n",
    "\n",
    "\n",
    "Feature Engineering: Correlation Analysis\n",
    "'''\n",
    "\n",
    "# Calculate pairwise correlation matrix\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import numpy as np\n",
    "\n",
    "# Assemble numerical features into a vector\n",
    "assembler = VectorAssembler(inputCols=numerical_cols, outputCol=\"features\")\n",
    "df_vector = assembler.transform(cleaned_df).select(\"features\")\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = Correlation.corr(df_vector, \"features\").head()[0].toArray()\n",
    "print(\"Correlation matrix:\\n\", correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Feature Engineering: Handle Categorical Variables with Pipeline\n",
    "\n",
    "StringIndex and then OneHotEncode the columns of string datatype\n",
    "'''\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# categorical_cols = [ 'mqtt_msgtype', 'tcp_flags', 'mqtt_hdrflags', 'mqtt_kalive', 'mqtt_msg',]\n",
    "\n",
    "# String \n",
    "stage_1 = StringIndexer(inputCol='mqtt_msgtype', outputCol='mqtt_msg_type_index')\n",
    "stage_2 = StringIndexer(inputCol='tcp_flags', outputCol='tcp_flags_index')\n",
    "stage_3 = StringIndexer(inputCol='mqtt_hdrflags', outputCol='mqtt_hdflags_index')\n",
    "stage_4 = StringIndexer(inputCol='mqtt_kalive', outputCol='mqtt_kalive_index')\n",
    "\n",
    "\n",
    "encoder_stage = OneHotEncoder(inputCols=['mqtt_msg_type_index', 'tcp_flags_index', 'mqtt_hdflags_index', \n",
    "                                     'mqtt_kalive_index',], \n",
    "                          outputCols=['mqtt_msg_type_encoded', 'tcp_flags_encoded', 'mqtt_hdflags_encoded', \n",
    "                                     'mqtt_kalive_encoded',])\n",
    "\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages=[stage_1, stage_2, stage_3, stage_4, encoder_stage])\n",
    "\n",
    "pipeline_model = pipeline.fit(cleaned_df)\n",
    "df_encoded = pipeline_model.transform(cleaned_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tcp_time_delta', 'tcp_len', 'mqtt_conack_val', 'mqtt_conflag_passwd', 'mqtt_conflag_uname', 'mqtt_len', 'target', 'set_type', 'mqtt_msg_type_encoded', 'tcp_flags_encoded', 'mqtt_hdflags_encoded', 'mqtt_kalive_encoded', 'numeric_vector', 'vectorized_features']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Feature Engineering: Combining features into a Single vector\n",
    "\n",
    "'''\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "\n",
    "# List of original string columns and _index columns to drop\n",
    "columns_to_drop = ['mqtt_msgtype', 'tcp_flags', 'mqtt_hdrflags', 'mqtt_kalive', 'mqtt_msg',\n",
    "                  'mqtt_msg_type_index', 'tcp_flags_index', 'mqtt_hdflags_index', 'mqtt_kalive_index']\n",
    "\n",
    "# Define feature list by dropping unnecessary columns and target column PlayResult\n",
    "features_only_df = df_encoded.drop(*columns_to_drop)\n",
    "feature_list = features_only_df.columns\n",
    "features_only_df.dtypes\n",
    "\n",
    "# Ensure all the columns are included in the list for VectorAssembler (both integer and vector types)\n",
    "binary_and_numeric_columns = ['mqtt_conflag_uname', 'mqtt_conflag_passwd', 'mqtt_conack_val', 'tcp_len', 'mqtt_len', 'tcp_time_delta']\n",
    "\n",
    "# Create a VectorAssembler for numeric columns\n",
    "numeric_assembler = VectorAssembler(\n",
    "    inputCols=binary_and_numeric_columns,\n",
    "    outputCol=\"numeric_vector\"\n",
    ")\n",
    "\n",
    "# Apply the assembler\n",
    "df_with_numeric_vector = numeric_assembler.transform(features_only_df)\n",
    "\n",
    "vector_columns = ['mqtt_msg_type_encoded', 'tcp_flags_encoded', 'mqtt_hdflags_encoded', 'mqtt_kalive_encoded']\n",
    "\n",
    "# Now, create a final VectorAssembler to combine the numeric vector and the already encoded vectors\n",
    "stage_final_assembler = VectorAssembler(\n",
    "    inputCols=[\"numeric_vector\"] + vector_columns,  # Combine numeric vector and the encoded vectors\n",
    "    outputCol=\"vectorized_features\"\n",
    ")\n",
    "\n",
    "# Stage where we scale the columns\n",
    "stage_scaler = StandardScaler(inputCol= 'vectorized_features', outputCol= 'features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: regParam=0.01, maxIter=1, Accuracy: 0.6674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: regParam=0.1, maxIter=5, Accuracy: 0.7311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: regParam=1.0, maxIter=10, Accuracy: 0.5766\n",
      "Best Model Parameters: regParam=0.1, maxIter=5\n",
      "Best Test Accuracy: 0.7311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " Predicted      0.0     1.0     2.0     3.0     4.0     5.0\n",
      "Actual                                                    \n",
      "0.0        3000000       0       0       0       0       0\n",
      "1.0         225759  254753       0       0     172  119316\n",
      "2.0         169298     127  430275       0      75     225\n",
      "3.0         357600       0       0  237600    1200    3600\n",
      "4.0         214260   49500    4440       0  187680  144120\n",
      "5.0         323175     525       0       0      75  276225\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Task 3\n",
    "\n",
    "Complete Pipeline from feature engineering above into \n",
    "\n",
    "SparkML Model 1: MultiClass Logistic Regression\n",
    "with Hyperparameter tuning to find the best model using the ParamGridBuilder\n",
    "for the regularization parameter and the number of iterations to learn.\n",
    "\n",
    "Format taken almost exactly from that executed in HW 5\n",
    "'''\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.feature import StandardScaler, StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DoubleType\n",
    "import pandas as pd\n",
    "\n",
    "binary_cols = ['mqtt_conflag_uname', 'mqtt_conflag_passwd', 'mqtt_conack_val']\n",
    "nominal_cols = ['mqtt_msgtype', 'tcp_flags', 'mqtt_hdrflags', 'mqtt_kalive']\n",
    "continuous_cols = ['tcp_time_delta', 'tcp_len', 'mqtt_len']\n",
    "label_col = 'label'  # Updated to use 'label' after indexing\n",
    "train_test_col = 'set_type'\n",
    "\n",
    "class FeatureTypeCaster(Transformer):  # this transformer will cast the columns as appropriate types\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        output_df = dataset\n",
    "        for col_name in binary_cols + continuous_cols:\n",
    "            output_df = output_df.withColumn(col_name, col(col_name).cast(DoubleType()))\n",
    "        return output_df\n",
    "\n",
    "class ColumnDropper(Transformer):  # this transformer drops unnecessary columns\n",
    "    def __init__(self, columns_to_drop=None):\n",
    "        super().__init__()\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        output_df = dataset\n",
    "        for col_name in self.columns_to_drop:\n",
    "            output_df = output_df.drop(col_name)\n",
    "        return output_df\n",
    "\n",
    "# Stage where columns are casted as appropriate types\n",
    "stage_typecaster = FeatureTypeCaster()\n",
    "\n",
    "# Stage to index the target column\n",
    "stage_label_indexer = StringIndexer(inputCol='target', outputCol='label')\n",
    "\n",
    "# Stage where nominal columns are transformed to index columns using StringIndexer\n",
    "nominal_id_cols = [x + \"_index\" for x in nominal_cols]\n",
    "nominal_onehot_cols = [x + \"_encoded\" for x in nominal_cols]\n",
    "stage_nominal_indexer = StringIndexer(inputCols=nominal_cols, outputCols=nominal_id_cols)\n",
    "\n",
    "# Stage where the index columns are further transformed using OneHotEncoder\n",
    "stage_nominal_onehot_encoder = OneHotEncoder(inputCols=nominal_id_cols, outputCols=nominal_onehot_cols)\n",
    "\n",
    "# Stage where all relevant features are assembled into a vector\n",
    "feature_cols = continuous_cols + binary_cols + nominal_onehot_cols\n",
    "stage_vector_assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"vectorized_features\")\n",
    "\n",
    "# Stage where we scale the columns\n",
    "stage_scaler = StandardScaler(inputCol='vectorized_features', outputCol='features')\n",
    "\n",
    "# Removing all unnecessary columns, including 'target'\n",
    "stage_column_dropper = ColumnDropper(columns_to_drop=nominal_cols + nominal_id_cols +\n",
    "                                     nominal_onehot_cols + binary_cols + continuous_cols + ['vectorized_features', 'target'])\n",
    "\n",
    "# Split the data based on the 'set_type' column\n",
    "train_df = cleaned_df.filter(cleaned_df[train_test_col] == 'train')\n",
    "test_df = cleaned_df.filter(cleaned_df[train_test_col] == 'test')\n",
    "\n",
    "# Define parameter grid manually\n",
    "paramGrid = [\n",
    "    {\"regParam\": 0.01, \"maxIter\": 1},\n",
    "    {\"regParam\": 0.1, \"maxIter\": 5},\n",
    "    {\"regParam\": 1.0, \"maxIter\": 10}\n",
    "]\n",
    "\n",
    "# Set up evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# Track best model and accuracy\n",
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "best_params = {}\n",
    "\n",
    "# Iterate over the parameter grid\n",
    "for params in paramGrid:\n",
    "    # Define logistic regression model with current parameters\n",
    "    mlr = LogisticRegression(featuresCol=\"features\", labelCol=label_col, family=\"multinomial\",\n",
    "                             regParam=params[\"regParam\"], maxIter=params[\"maxIter\"])\n",
    "\n",
    "    # Assemble the Pipeline\n",
    "    pipeline = Pipeline(stages=[\n",
    "        stage_typecaster,\n",
    "        stage_label_indexer,\n",
    "        stage_nominal_indexer,\n",
    "        stage_nominal_onehot_encoder,\n",
    "        stage_vector_assembler,\n",
    "        stage_scaler,\n",
    "        stage_column_dropper,\n",
    "        mlr\n",
    "    ])\n",
    "\n",
    "    # Train the model on the training data\n",
    "    pipeline_model = pipeline.fit(train_df)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    predictions = pipeline_model.transform(test_df)\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "    print(f\"Parameters: regParam={params['regParam']}, maxIter={params['maxIter']}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Update best model if current model is better\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = pipeline_model\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best Model Parameters: regParam={best_params['regParam']}, maxIter={best_params['maxIter']}\")\n",
    "print(f\"Best Test Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Optional: Confusion Matrix for the best model\n",
    "predictions_pd = best_model.transform(test_df).select(label_col, \"prediction\").toPandas()\n",
    "confusion_matrix = pd.crosstab(predictions_pd[label_col], predictions_pd['prediction'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Label Index to Original Target Mapping:\n",
    "0.0: legitimate\n",
    "1.0: bruteforce  42% correct, 38% falsely legitimate (false negative), 20% wrongly labeled\n",
    "2.0: dos         72% correct, 28% falsely legitimate (false negative), <1% wrongly labeled\n",
    "3.0: flood       40% correct, 60% falsely legitimate (false negative), <1% wrongly labeled\n",
    "4.0: malformed   31% correct, 36% falsely legitimate (false negative), 33% wrongly labeled\n",
    "5.0: slowite     46% correct, 54% falsely legitimate (false negative), <1% wrongly labeled\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 109:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Index to Original Target Mapping:\n",
      "0.0: legitimate\n",
      "1.0: bruteforce\n",
      "2.0: dos\n",
      "3.0: flood\n",
      "4.0: malformed\n",
      "5.0: slowite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# After fitting the pipeline\n",
    "pipeline_model = pipeline.fit(train_df)\n",
    "\n",
    "# Access the StringIndexerModel for the 'target' column\n",
    "label_indexer_model = pipeline_model.stages[1]  # Adjust index if necessary\n",
    "\n",
    "# Retrieve the labels\n",
    "labels = label_indexer_model.labels\n",
    "\n",
    "# Create a mapping from index to label\n",
    "index_to_label = {float(index): label for index, label in enumerate(labels)}\n",
    "\n",
    "# Display the mapping\n",
    "print(\"Label Index to Original Target Mapping:\")\n",
    "for index, label in index_to_label.items():\n",
    "    print(f\"{index}: {label}\")\n",
    "\n",
    "# Now, you can interpret your confusion matrix using this mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: smoothing=1.0, Accuracy: 0.7291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: smoothing=0.5, Accuracy: 0.7291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: smoothing=0.1, Accuracy: 0.7291\n",
      "Best Model Parameters: smoothing=1.0\n",
      "Best Test Accuracy: 0.7291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " Predicted      0.0     1.0     2.0     3.0     4.0     5.0\n",
      "Actual                                                    \n",
      "0.0        3000000       0       0       0       0       0\n",
      "1.0         225759  254925       0       0       0  119316\n",
      "2.0         169298     202  430275       0       0     225\n",
      "3.0         336000    1200       0  259200       0    3600\n",
      "4.0         214260   83400    2160       0  153840  146340\n",
      "5.0         323175     525       0       0      75  276225\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Task 3\n",
    "\n",
    "SparkML Model 2: MultiClass Naive Bayes\n",
    "with Hyperparameter tuning to find the best model using the smoothing\n",
    "\n",
    "Format taken almost exactly from above and data engineering nearly already complete\n",
    "'''\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "minmax_scaler = MinMaxScaler(inputCol=\"vectorized_features\", outputCol=\"features\")\n",
    "from pyspark.sql.functions import abs\n",
    "\n",
    "class FeatureTypeCaster(Transformer):  # this transformer will cast the columns as appropriate types\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def _transform(self, dataset):\n",
    "        output_df = dataset\n",
    "        for col_name in binary_cols + continuous_cols:\n",
    "            output_df = output_df.withColumn(col_name, abs(col(col_name).cast(DoubleType())))\n",
    "        return output_df\n",
    "\n",
    "# Define parameter grid manually for Naive Bayes\n",
    "paramGrid = [\n",
    "    {\"smoothing\": 1.0},\n",
    "    {\"smoothing\": 0.5},\n",
    "    {\"smoothing\": 0.1}\n",
    "]\n",
    "\n",
    "stage_vector_assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"vectorized_features\")\n",
    "NB_stage_minmax_scaler = MinMaxScaler(inputCol=\"vectorized_features\", outputCol=\"features\")\n",
    "# Set up evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "best_NB_model = None\n",
    "best_NB_accuracy = 0.0\n",
    "best_NB_params = {}\n",
    "\n",
    "# Cache the DataFrames after loading\n",
    "train_df = cleaned_df.filter(cleaned_df[train_test_col] == 'train').cache()\n",
    "test_df = cleaned_df.filter(cleaned_df[train_test_col] == 'test').cache()\n",
    "\n",
    "# Iterate over the parameter grid\n",
    "for params in paramGrid:\n",
    "    # Define Naive Bayes model with current parameters\n",
    "    nb = NaiveBayes(featuresCol=\"features\", labelCol=label_col, modelType=\"multinomial\", smoothing=params[\"smoothing\"])\n",
    "\n",
    "    # Assemble the Pipeline\n",
    "    pipeline = Pipeline(stages=[\n",
    "        stage_typecaster,\n",
    "        stage_label_indexer,           \n",
    "        stage_nominal_indexer,\n",
    "        stage_nominal_onehot_encoder,\n",
    "        stage_vector_assembler,\n",
    "        NB_stage_minmax_scaler,\n",
    "        stage_column_dropper,\n",
    "        nb\n",
    "    ])\n",
    "\n",
    "    # Train the model on the training data\n",
    "    pipeline_model = pipeline.fit(train_df)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    predictions = pipeline_model.transform(test_df)\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "    print(f\"Parameters: smoothing={params['smoothing']}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Update best model if current model is better\n",
    "    if accuracy > best_NB_accuracy:\n",
    "        best_NB_accuracy = accuracy\n",
    "        best_NB_model = pipeline_model\n",
    "        best_NB_params['smoothing'] = params['smoothing']\n",
    "\n",
    "train_df.unpersist()\n",
    "test_df.unpersist()\n",
    "print(f\"Best Model Parameters: smoothing={best_NB_params['smoothing']}\")\n",
    "print(f\"Best Test Accuracy: {best_NB_accuracy:.4f}\")\n",
    "\n",
    "# Optional: Confusion Matrix for the best model\n",
    "predictions_pd = best_NB_model.transform(test_df).select(label_col, \"prediction\").toPandas()\n",
    "confusion_matrix = pd.crosstab(predictions_pd[label_col], predictions_pd['prediction'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Label Index to Original Target Mapping:\n",
    "0.0: legitimate\n",
    "1.0: bruteforce  42% correct, 38% falsely legitimate (false negative), 20% wrongly labeled\n",
    "2.0: dos         72% correct, 28% falsely legitimate (false negative), <1% wrongly labeled\n",
    "3.0: flood       43% correct, 56% falsely legitimate (false negative), <1% wrongly labeled\n",
    "4.0: malformed   25% correct, 36% falsely legitimate (false negative), 39% wrongly labeled\n",
    "5.0: slowite     46% correct, 54% falsely legitimate (false negative), <1% wrongly labeled\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/miniconda3/lib/python3.11/site-packages (1.3.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (2023.12.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch)\n",
      "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/miniconda3/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m134.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12.1\n",
      "    Uninstalling sympy-1.12.1:\n",
      "      Successfully uninstalled sympy-1.12.1\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1 torchvision-0.20.1 triton-3.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder, OneHotEncoder, StandardScaler\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Task 3\n",
    "\n",
    "Torch Model 1: Multinomial Logistic Regression\n",
    "with Hyperparameter tuning to find the best model using the paramgrid\n",
    "\n",
    "Data engineering taken from HW 6\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Convert Spark DataFrames to Pandas DataFrames\n",
    "train_pd = train_df.toPandas()\n",
    "test_pd = test_df.toPandas()\n",
    "\n",
    "# Define columns\n",
    "binary_cols = ['mqtt_conflag_uname', 'mqtt_conflag_passwd', 'mqtt_conack_val']\n",
    "nominal_cols = ['mqtt_msgtype', 'tcp_flags', 'mqtt_hdrflags', 'mqtt_kalive']\n",
    "continuous_cols = ['tcp_time_delta', 'tcp_len', 'mqtt_len']\n",
    "label_col = 'target'  # Original target column\n",
    "\n",
    "# Feature Type Casting\n",
    "for col in binary_cols + continuous_cols:\n",
    "    train_pd[col] = pd.to_numeric(train_pd[col])\n",
    "    test_pd[col] = pd.to_numeric(test_pd[col])\n",
    "\n",
    "# Encode the Target Variable\n",
    "label_encoder = LabelEncoder()\n",
    "train_pd['label'] = label_encoder.fit_transform(train_pd[label_col])\n",
    "test_pd['label'] = label_encoder.transform(test_pd[label_col])\n",
    "\n",
    "# Drop original target column\n",
    "train_pd.drop(columns=[label_col], inplace=True)\n",
    "test_pd.drop(columns=[label_col], inplace=True)\n",
    "\n",
    "# Label Encoding and One-Hot Encoding for Nominal Features\n",
    "for col in nominal_cols:\n",
    "    le = LabelEncoder()\n",
    "    train_pd[col + '_index'] = le.fit_transform(train_pd[col])\n",
    "    test_pd[col + '_index'] = le.transform(test_pd[col])\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "train_encoded = onehot_encoder.fit_transform(train_pd[[col + '_index' for col in nominal_cols]])\n",
    "test_encoded = onehot_encoder.transform(test_pd[[col + '_index' for col in nominal_cols]])\n",
    "\n",
    "nominal_onehot_cols = onehot_encoder.get_feature_names_out([col + '_index' for col in nominal_cols])\n",
    "train_onehot_df = pd.DataFrame(train_encoded, columns=nominal_onehot_cols)\n",
    "test_onehot_df = pd.DataFrame(test_encoded, columns=nominal_onehot_cols)\n",
    "\n",
    "train_onehot_df.reset_index(drop=True, inplace=True)\n",
    "test_onehot_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Assemble Features\n",
    "train_features = train_pd[continuous_cols + binary_cols].reset_index(drop=True)\n",
    "test_features = test_pd[continuous_cols + binary_cols].reset_index(drop=True)\n",
    "train_features = pd.concat([train_features, train_onehot_df], axis=1)\n",
    "test_features = pd.concat([test_features, test_onehot_df], axis=1)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "# Prepare Labels\n",
    "train_labels = train_pd['label'].values\n",
    "test_labels = test_pd['label'].values\n",
    "\n",
    "# Create PyTorch Datasets and DataLoaders\n",
    "class MQTTDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.X = torch.tensor(features, dtype=torch.float32)\n",
    "        self.y = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset = MQTTDataset(train_features_scaled, train_labels)\n",
    "test_dataset = MQTTDataset(test_features_scaled, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Define the Model\n",
    "input_size = train_features.shape[1]\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "class MultinomialLogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MultinomialLogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "param_grid = [\n",
    "    {'lr': 0.01, 'num_epochs': 1},\n",
    "    {'lr': 0.1, 'num_epochs': 2},\n",
    "    {'lr': 1.0, 'num_epochs': 3}\n",
    "]\n",
    "\n",
    "best_torch_lr_accuracy = 0.0\n",
    "best_torch_lr_params = {}\n",
    "best_torch_lr_model_state = None\n",
    "\n",
    "for params in param_grid:\n",
    "    model = MultinomialLogisticRegression(input_size, num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=params['lr'])\n",
    "    num_epochs = params['num_epochs']\n",
    "    \n",
    "    # Training Loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            outputs = model(batch_X)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Parameters: lr={params['lr']}, num_epochs={params['num_epochs']}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_torch_lr_accuracy = accuracy\n",
    "        best_torch_lr_params = params\n",
    "        best_torch_lr_model_state = model.state_dict()\n",
    "\n",
    "print(f\"Best Parameters: lr={best_torch_lr_params['lr']}, num_epochs={best_torch_lr_params['num_epochs']}\")\n",
    "print(f\"Best Test Accuracy: {best_torch_lr_accuracy:.4f}\")\n",
    "\n",
    "# Load the best model state\n",
    "model.load_state_dict(best_torch_lr_model_state)\n",
    "\n",
    "# Confusion Matrix for the best model\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
